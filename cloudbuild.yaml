steps:

  # Step 6: Fetch the OLD active revision (before deploying a new version)
  - name: 'gcr.io/cloud-builders/gcloud'
    id: 'Fetch Old Revision'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        gcloud run revisions list \
          --service=my-mlflow-app \
          --region=us-west1 \
          --filter="status.conditions.type['Active'].status:'True'" \
          --format="value(metadata.name)" > /workspace/active_revisions.txt

        echo "Checking active revisions..."
        cat /workspace/active_revisions.txt

        if [ "$(wc -l < /workspace/active_revisions.txt)" -gt 1 ]; then
          echo "ERROR: More than one active revision found!"
          exit 1  # Stop the build process
        fi

        cat /workspace/active_revisions.txt > /workspace/old_revision.txt
        echo "Old active revision: $(cat /workspace/old_revision.txt)"
  

  # Step 1: Run Tests
  - name: "python:3.12"
    id: "run-tests"
    entrypoint: "sh"
    args:
      - "-c"
      - |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        echo "Running tests..."
        python -m pytest tests/ || exit 1  # Stop build if tests fail

  # Step 2: Build the Training Docker Image
  - name: 'gcr.io/cloud-builders/docker'
    id: 'Build Training Image'
    args:
      - 'build'
      - '--network=cloudbuild'
      - '-t'
      - 'gcr.io/$PROJECT_ID/training-image'
      - '-f'
      - 'Dockerfile-training'
      - '.'

  # Step 3: Fetch serving account keys
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    id: 'Fetch Service Account Key'
    entrypoint: 'gsutil'
    args:
      - 'cp'
      - 'gs://service-account-key-training/keys.json'
      - '/workspace/service-account-key.json'  # Ensure the file name matches throughout

  # Step 4: run docker image
  - name: 'gcr.io/cloud-builders/docker'
    id: 'Run Docker Container'
    args:
      - 'run'
      - '--rm'
      - '-v'
      - '/workspace:/workspace'  # This mounts the Cloud Build workspace inside the container
      - '-e'
      - 'GOOGLE_APPLICATION_CREDENTIALS=/workspace/service-account-key.json'
      - 'gcr.io/$PROJECT_ID/training-image'


  # Step 5: Build App Docker Image
  - name: 'gcr.io/cloud-builders/docker'
    id: 'Build App Image'
    args:
      - 'build'
      - '-t'
      - 'gcr.io/$PROJECT_ID/app-image'
      - '-f'
      - 'Dockerfile-app'
      - '.'

  # Step 6: Push App Image to Google Container Registry (GCR)
  - name: 'gcr.io/cloud-builders/docker'
    id: 'Push App Image to GCR'
    args:
      - 'push'
      - 'gcr.io/$PROJECT_ID/app-image'

  # Step 7: Deploy App Image to Cloud Run (Only this service runs continuously)
  - name: 'gcr.io/cloud-builders/gcloud'
    id: 'Deploy to Cloud Run'
    args:
      - 'run'
      - 'deploy'
      - 'my-mlflow-app'
      - '--image'
      - 'gcr.io/$PROJECT_ID/app-image'
      - '--platform'
      - 'managed'
      - '--region'
      - 'us-west1'
      - '--allow-unauthenticated'
      - '--memory'
      - '1Gi'
      - '--set-env-vars'
      - 'MODEL_TYPE=challenger'
      - '--no-traffic'

  # Step 6: Fetch the NEW revision (latest created revision)
  - name: 'gcr.io/cloud-builders/gcloud'
    id: 'Fetch New Revision'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        gcloud run revisions list \
          --service=my-mlflow-app \
          --region=us-west1 \
          --format="value(metadata.name)" \
          --sort-by="~createTime" | head -n1 > /workspace/new_revision.txt
        echo "New revision: $(cat /workspace/new_revision.txt)"


# Step 7: Assign 80% traffic to the OLD revision and 20% to the NEW revision
  - name: 'gcr.io/cloud-builders/gcloud'
    id: 'Set Traffic Split'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        echo "Routing traffic: $(cat /workspace/old_revision.txt)=50%, $(cat /workspace/new_revision.txt)=50%"
        gcloud run services update-traffic my-mlflow-app \
          --region us-west1 \
          --to-revisions="$(cat /workspace/old_revision.txt)=50,$(cat /workspace/new_revision.txt)=50"


options:
  logging: CLOUD_LOGGING_ONLY
